{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c2f08f5-6dd9-4958-855b-3f51b9e8a7f1",
      "metadata": {
        "id": "0c2f08f5-6dd9-4958-855b-3f51b9e8a7f1"
      },
      "source": [
        "# Title: Development of an Automatic Sentiment Analysis Tool for Urdu Text on Social Media Platforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d8f3b0-ea37-47d2-92ab-a8a33fa071d4",
      "metadata": {
        "id": "b5d8f3b0-ea37-47d2-92ab-a8a33fa071d4"
      },
      "source": [
        "# Phase 1: Text Preprocessing for Urdu Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13fb1a67-3e27-4fb5-88f1-55e87cf182d9",
      "metadata": {
        "id": "13fb1a67-3e27-4fb5-88f1-55e87cf182d9"
      },
      "source": [
        "Step 1: Import Libraries and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1533ee3-f961-4877-8db3-213686cdc59c",
      "metadata": {
        "id": "b1533ee3-f961-4877-8db3-213686cdc59c",
        "outputId": "2d3eb818-e0c5-4a23-8840-40b7ace7c220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            urdu_text  is_sarcastic  \\\n",
            "0   🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0   \n",
            "1   چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0   \n",
            "2   کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0   \n",
            "3                                        نہیں پائین 😎           0.0   \n",
            "4    `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0   \n",
            "5         قابل اعتبار ہی اکثر قاتل اعتبار ہوتے ہیں 💔🔥           1.0   \n",
            "6       انساں کو تھکا دیتا ہے سوچوں کا سفر بھی ... 🍁🥀           0.0   \n",
            "7                               حامد میر صاحب ویلڈن👏😊           0.0   \n",
            "8   یار وچارہ ویلا ہوندا ہے اس آرے لگا ہویا ہے😂😂 ت...           1.0   \n",
            "9            یہ سمجھتے ہیں سارا پاکستان بیوقوف ھے 😂😂😂           1.0   \n",
            "10                      تسی لڑاںٔی کروانی ساڈی کی 😂😂😂           0.0   \n",
            "11                       پائن دوبارہ فالو کرئیے..؟؟😆🙄           0.0   \n",
            "12  کتنی مہنگائی ہے الو دوسو روپے درجن کدو 80روپے ...           1.0   \n",
            "13   😍عشق جب تم کو راس آۓ گا 💔زخم کھاٶ گے 😊مُسکراٶ گے           1.0   \n",
            "14                                چونا ایسا ہی ہوتا 😂           0.0   \n",
            "15  خاتم_النبیین_محمدﷺ Surat 73 سورة المزمل Ayt 20...           0.0   \n",
            "16  اب بس بھی کرو بیچارے کی پہلے ہی دو بیویاں ہیے ...           1.0   \n",
            "17  پتہ نہیں کیا ہورہا ہے سی سی کی بورڈ کو زنگ لگ ...           1.0   \n",
            "18  اللہ آپ کو اپنی رحمتوں کے سائے میں رکھے اور مک...           0.0   \n",
            "19  آرمی چیف کا نوٹس۔ اب مجرم اپنے جرائیم پر خود ن...           0.0   \n",
            "20  کھوتی دیا بچیا،تیری عزت کیتی اے،تیری قدر کیتی ...           1.0   \n",
            "21  فوج سیاست سے دور رہے۔ بلاول زرداری فوج کراچی و...           1.0   \n",
            "22                              شکریہ لڑکی 😍جیتی رہ 😂           0.0   \n",
            "23   صدائیں درودوں کی آتی رہینگی جنہیں سن کر دل شا...           0.0   \n",
            "24                یہ ووٹ کی بجائے ووٹر کو عزّت دیں ✌️           1.0   \n",
            "25  2004 میں ایک نشئی نے کہا تھا کہ ... .. اگر اسٹ...           1.0   \n",
            "26  مشکل ہے لیکن ناممکن نہیں اگر کامران صاحب کوشش ...           0.0   \n",
            "27   میں نے پورے دو ہفتے سے سالن روٹی نہیں کھایا ہ...           0.0   \n",
            "28                                  تو رہنے دے پھر 😂😂           1.0   \n",
            "29  وھ کوئی بھی ھو بیشک میں ھے ھو وہ 🐕 کیمنا حرام ...           1.0   \n",
            "30   میں ماضی کی انتہائی بے وقوف اور حال کی سمجھدا...           0.0   \n",
            "31                                    آمین ثمہ آمین 😍           0.0   \n",
            "32                   جیتھے دی کھوتی وتھے آ کھلوتی 😜😜😜           1.0   \n",
            "33  یہ اسمبلی بغیر ڈیزل کے چل رہی ہے کیونکہ اِسکو ...           1.0   \n",
            "34  عجیب بات کی کامران خان صاحب نے۔ پنگا بھی ان سے...           0.0   \n",
            "35                                          گڈ ناٸیٹ😁           0.0   \n",
            "36  دروازے پر بہت اتارتے تھے پہلے اب تو خود کو ہی ...           1.0   \n",
            "37    ویسے اپنے پیر پر کلہاڑی مارنا کوئ ان سے سیکھے 😂           1.0   \n",
            "38              آپ دلہن کی پھپھو ہیں میری نہیں 😏😏😂🤣🤣🤣           0.0   \n",
            "39        ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ 😂😂😂😂           0.0   \n",
            "40  میں محمد ندیم ملک بطور ایک عام پاکستانی بلاول ...           1.0   \n",
            "41  قطری نانی ۔۔اور بلو رانی کے ذلیل ہونے کا وقت ہ...           1.0   \n",
            "42  اچھا بھائیوں کو زیادہ ویلکم کر سکتی تم لڑکی بہ...           0.0   \n",
            "43                  موٹی چڑیل ٹویٹ دیکھو کس کی ہے 😂😂😂           0.0   \n",
            "44                         ایتھے تے سب ہی جج نے۔۔۔😂😂😂           1.0   \n",
            "45  اک محترمہ سارا دن پاک فوج کے خلاف بکواس کر کے ...           1.0   \n",
            "46  ان کو لگتا ہے کہ انکے دیوتا کی طرح پورا پاکستا...           0.0   \n",
            "47  ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا 😂😂🙏🙏🙏🙏 لگدا اے...           0.0   \n",
            "48  ضرورت ہی نہیں اس کو الٹی کھوپڑی کی بات ایک کان...           1.0   \n",
            "49   سنا تھا 1 اکیلا ہوتا ہے اور ساتھ 1 ہو تو 11 گ...           1.0   \n",
            "\n",
            "    Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
            "0          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "1          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "2          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "3          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "4          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "5          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "6          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "7          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "8          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "9          NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "10         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "11         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "12         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "13         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "14         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "15         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "16         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "17         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "18         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "19         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "20         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "21         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "22         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "23         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "24         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "25         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "26         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "27         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "28         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "29         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "30         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "31         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "32         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "33         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "34         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "35         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "36         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "37         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "38         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "39         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "40         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "41         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "42         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "43         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "44         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "45         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "46         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "47         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "48         NaN         NaN         NaN         NaN        NaN         NaN  \n",
            "49         NaN         NaN         NaN         NaN        NaN         NaN  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Applications/anaconda3/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
            "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from LughaatNLP import LughaatNLP\n",
        "processor = LughaatNLP()\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('urdu_sarcastic_dataset.csv')\n",
        "print(data.head(50))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70011036-5d6c-4664-a5ab-203fa485dbd9",
      "metadata": {
        "id": "70011036-5d6c-4664-a5ab-203fa485dbd9"
      },
      "source": [
        "Step 2: Define Custom Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566d66f8-9a1b-401f-b56e-94067be7b9d9",
      "metadata": {
        "id": "566d66f8-9a1b-401f-b56e-94067be7b9d9"
      },
      "source": [
        "Step 3: Create Stopword Removal Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "688b7956-5983-434d-916a-42499d5c1ba0",
      "metadata": {
        "id": "688b7956-5983-434d-916a-42499d5c1ba0",
        "outputId": "e7eb9367-a58e-4c7c-c189-d768ab614241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           urdu_text  \\\n",
            "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
            "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
            "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
            "3                                       نہیں پائین 😎   \n",
            "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0                 🤣😂😂 لینے شادی فسادن ٹھیک کوجی 😐😐😐🤣  \n",
            "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂  \n",
            "2  کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...  \n",
            "3                                            پائین 😎  \n",
            "4       `` مراد علی شاہ بھیس ڈی آئی آئی '' حامد میر😁  \n"
          ]
        }
      ],
      "source": [
        "sentiment_words = [\n",
        "    'نہیں', 'برا', 'اچھا', 'خوش', 'غمگین', 'محبت', 'نفرت',\n",
        "    'خوشی', 'مایوسی', 'شکریہ', 'تکلیف', 'خوف', 'کامیابی',\n",
        "    'ناکامی', 'امید', 'خواب', 'صبر', 'غصہ', 'شرم', 'عزت',\n",
        "    'تعجب', 'تشکر', 'دوستی', 'تجربہ', 'رنج', 'سکون',\n",
        "    'محبت', 'غمی', 'مسکراہٹ', 'خوشبو', 'غفلت', 'آزادی',\n",
        "    'دوستی'\n",
        "]\n",
        "sentiment_set = set(sentiment_words)\n",
        "\n",
        "def remove_stopwords(text, sentiment_stopwords):\n",
        "   filtered_text = processor.remove_stopwords(text)\n",
        "    # Retain sentiment-carrying stopwords\n",
        "   filtered_text = \" \".join([word for word in filtered_text.split() if word not in sentiment_stopwords])\n",
        "\n",
        "   return filtered_text\n",
        "\n",
        "data['cleaned_text'] = data['urdu_text'].apply(\n",
        "    lambda x: remove_stopwords(x, sentiment_set) if pd.notnull(x) else x\n",
        ")\n",
        "\n",
        "print(data[['urdu_text', 'cleaned_text']].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8351d5c-609c-4723-8375-c99331d5fce7",
      "metadata": {
        "id": "d8351d5c-609c-4723-8375-c99331d5fce7"
      },
      "source": [
        "Step 4: Remove unnecessary punctuation, URLs, hashtags, and handle emojis appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c33bc9-79cd-4fa6-8904-2602d9e5730e",
      "metadata": {
        "id": "36c33bc9-79cd-4fa6-8904-2602d9e5730e",
        "outputId": "b3e36120-d8e6-4e87-df2d-18a345849168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     positivepositivepositive لینے شادی فسادن ٹھیک ...\n",
            "1     چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
            "2     کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
            "3                                        پائین positive\n",
            "4                مراد علی شاہ بھیس ڈی آئی آئی  حامد میر\n",
            "5                      قابل اعتبار قاتل اعتبار negative\n",
            "6                              انساں تھکا سوچوں سفر    \n",
            "7                        حامد میر ویلڈنpositivepositive\n",
            "8     یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...\n",
            "9     سمجھتے سارا پاکستان بیوقوف ھے positivepositive...\n",
            "10      تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11        پائن دوبارہ فالو کرئیے   ؟ ؟ positivenegative\n",
            "12    کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...\n",
            "13    positiveعشق راس آۓ negativeزخم کھاٶ گے positiv...\n",
            "14                                        چونا positive\n",
            "15    خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...\n",
            "16                بیچارے بیویاں ہیے تیسری ٹرائ positive\n",
            "17                پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                اللہ رحمتوں سائے مکمل صحت یاب فرمائے \n",
            "19     آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20    کھوتی بچیا،تیری اے،تیری قدر اے ۔ شکر بونڈ نئیں...\n",
            "21    فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...\n",
            "22                           لڑکی positiveجیتی positive\n",
            "23    صدائیں درودوں رہینگی سن دل شاد گا، خدا اہلسنت ...\n",
            "24                                ووٹ بجائے ووٹر عزّت ️\n",
            "25    2004 نشئی کہا      اسٹیبلشمنٹ کتا وزیراعظم 201...\n",
            "26               مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27    پورے ہفتے سالن روٹی کھایا neutralneutralکوئی حال \n",
            "28                                     positivepositive\n",
            "29    وھ کوئی ھو بیشک ھے ھو  کیمنا حرام ھو حق بات کا...\n",
            "30    ماضی انتہائی بے وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                               آمین ثمہ آمین positive\n",
            "32    جیتھے کھوتی وتھے آ کھلوتی positivepositiveposi...\n",
            "33    اسمبلی ڈیزل چل اِسکو گدھا  ھے گدھے ڈیزل  ڈنڈے ...\n",
            "34    عجیب بات کامران خان ۔ پنگا گولیاں محو رقص ۔ پت...\n",
            "35                                             گڈ ناٸیٹ\n",
            "36    دروازے اتارتے تھپڑ لگاتے positivepositiveposit...\n",
            "37                      کلہاڑی مارنا کوئ سیکھے positive\n",
            "38    دلہن پھپھو neutralneutralpositivepositiveposit...\n",
            "39    ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ positiv...\n",
            "40    محمد ندیم ملک بطور عام پاکستانی بلاول زرداری د...\n",
            "41    قطری نانی ۔ ۔ بلو رانی ذلیل وقت چاہتا ۔ ۔ ۔ ۔ ...\n",
            "42    بھائیوں ویلکم لڑکی بہنوں کرا نہیںneutralneutra...\n",
            "43              موٹی چڑیل ٹویٹ positivepositivepositive\n",
            "44           ایتھے تے جج ۔ ۔ ۔ positivepositivepositive\n",
            "45    سارا دن پاک فوج خلاف بکواس رات فوجی گل ۔ ۔ ۔ p...\n",
            "46    لگتا دیوتا پورا پاکستان  لکیروں  سہارے سوچتا ب...\n",
            "47    ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا positivepositi...\n",
            "48    ضرورت الٹی کھوپڑی بات کان سنو نکال positivepos...\n",
            "49    سنا 1 اکیلا 1 11 گیارہ ۔ تاریخ دفعہ 11 1 برباد...\n",
            "Name: cleaned_text1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import emoji\n",
        "\n",
        "# Emoji sentiment dictionary\n",
        "emoji_sentiment_dict = {\n",
        "    '😊': 'positive',\n",
        "    '😞': 'negative',\n",
        "    '❤️': 'positive',\n",
        "    '📚': 'neutral',\n",
        "    '😭': 'negative',\n",
        "    '🌹': 'positive',\n",
        "    '😂': 'positive',\n",
        "    '😢': 'negative',\n",
        "    '🥺': 'negative',\n",
        "    '😡': 'negative',\n",
        "    '😍': 'positive',\n",
        "    '👍': 'positive',\n",
        "    '👎': 'negative',\n",
        "    '🎉': 'positive',\n",
        "    '😱': 'negative',\n",
        "    '😌': 'positive',\n",
        "    '😏': 'neutral',\n",
        "    '🤔': 'neutral',\n",
        "    '🙌': 'positive',\n",
        "    '🤗': 'positive',\n",
        "    '💔': 'negative',\n",
        "    '🌈': 'positive',\n",
        "    '☹️': 'negative',\n",
        "    '🥳': 'positive',\n",
        "    '😎': 'positive',\n",
        "    '😴': 'neutral',\n",
        "    '😋': 'positive',\n",
        "    '🤑': 'positive',\n",
        "    '🤩': 'positive',\n",
        "    '🤝': 'positive',\n",
        "    '😬': 'neutral',\n",
        "    '🙈': 'neutral',\n",
        "    '🌍': 'neutral',\n",
        "    '🦋': 'positive',\n",
        "    '🥲': 'positive',\n",
        "    '😜': 'positive',\n",
        "    '🙄': 'negative',\n",
        "    '😆': 'positive',\n",
        "    '👏': 'positive',\n",
        "    '🤣': 'positive',\n",
        "    '✌️': 'neutral',\n",
        "    '😕': 'neutral'\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):  # Check if the input is a string\n",
        "        return ''  # Return an empty string if it's not\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "\n",
        "    text = re.sub(r\"#\\w+\", '', text)\n",
        "    # Remove punctuations (except those in the sentiment dict)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    cleaned_text = []\n",
        "    for char in text:\n",
        "        if char in emoji_sentiment_dict:\n",
        "            cleaned_text.append(emoji_sentiment_dict[char])\n",
        "        elif not emoji.is_emoji(char):\n",
        "            cleaned_text.append(char)  #\n",
        "\n",
        "    return ''.join(cleaned_text)\n",
        "\n",
        "# Apply cleaning function\n",
        "data['cleaned_text1'] = data['cleaned_text'].apply(clean_text)\n",
        "\n",
        "# Print the results\n",
        "print(data['cleaned_text1'].head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d51c6c-dc0c-4aa5-9ca1-8714cd71bdc2",
      "metadata": {
        "id": "49d51c6c-dc0c-4aa5-9ca1-8714cd71bdc2"
      },
      "source": [
        "Step 5: Handle Short Conversations : filter out very short posts or those with less than three words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c79d4cc-78de-4772-82c1-16273e5a748a",
      "metadata": {
        "id": "8c79d4cc-78de-4772-82c1-16273e5a748a",
        "outputId": "0e38986f-a072-47ba-c55f-80ce67ca4e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     positivepositivepositive لینے شادی فسادن ٹھیک ...\n",
            "1     چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
            "2     کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
            "4                مراد علی شاہ بھیس ڈی آئی آئی  حامد میر\n",
            "5                      قابل اعتبار قاتل اعتبار negative\n",
            "6                              انساں تھکا سوچوں سفر    \n",
            "7                        حامد میر ویلڈنpositivepositive\n",
            "8     یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...\n",
            "9     سمجھتے سارا پاکستان بیوقوف ھے positivepositive...\n",
            "10      تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11        پائن دوبارہ فالو کرئیے   ؟ ؟ positivenegative\n",
            "12    کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...\n",
            "13    positiveعشق راس آۓ negativeزخم کھاٶ گے positiv...\n",
            "15    خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...\n",
            "16                بیچارے بیویاں ہیے تیسری ٹرائ positive\n",
            "17                پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                اللہ رحمتوں سائے مکمل صحت یاب فرمائے \n",
            "19     آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20    کھوتی بچیا،تیری اے،تیری قدر اے ۔ شکر بونڈ نئیں...\n",
            "21    فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...\n",
            "22                           لڑکی positiveجیتی positive\n",
            "23    صدائیں درودوں رہینگی سن دل شاد گا، خدا اہلسنت ...\n",
            "24                                ووٹ بجائے ووٹر عزّت ️\n",
            "25    2004 نشئی کہا      اسٹیبلشمنٹ کتا وزیراعظم 201...\n",
            "26               مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27    پورے ہفتے سالن روٹی کھایا neutralneutralکوئی حال \n",
            "29    وھ کوئی ھو بیشک ھے ھو  کیمنا حرام ھو حق بات کا...\n",
            "30    ماضی انتہائی بے وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                               آمین ثمہ آمین positive\n",
            "32    جیتھے کھوتی وتھے آ کھلوتی positivepositiveposi...\n",
            "33    اسمبلی ڈیزل چل اِسکو گدھا  ھے گدھے ڈیزل  ڈنڈے ...\n",
            "34    عجیب بات کامران خان ۔ پنگا گولیاں محو رقص ۔ پت...\n",
            "36    دروازے اتارتے تھپڑ لگاتے positivepositiveposit...\n",
            "37                      کلہاڑی مارنا کوئ سیکھے positive\n",
            "38    دلہن پھپھو neutralneutralpositivepositiveposit...\n",
            "39    ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ positiv...\n",
            "40    محمد ندیم ملک بطور عام پاکستانی بلاول زرداری د...\n",
            "41    قطری نانی ۔ ۔ بلو رانی ذلیل وقت چاہتا ۔ ۔ ۔ ۔ ...\n",
            "42    بھائیوں ویلکم لڑکی بہنوں کرا نہیںneutralneutra...\n",
            "43              موٹی چڑیل ٹویٹ positivepositivepositive\n",
            "44           ایتھے تے جج ۔ ۔ ۔ positivepositivepositive\n",
            "45    سارا دن پاک فوج خلاف بکواس رات فوجی گل ۔ ۔ ۔ p...\n",
            "46    لگتا دیوتا پورا پاکستان  لکیروں  سہارے سوچتا ب...\n",
            "47    ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا positivepositi...\n",
            "48    ضرورت الٹی کھوپڑی بات کان سنو نکال positivepos...\n",
            "49    سنا 1 اکیلا 1 11 گیارہ ۔ تاریخ دفعہ 11 1 برباد...\n",
            "50                 زندگی مصروف بھول یاد نہیں اردو  زبان\n",
            "52                  ہور ٹرک  positive positive positive\n",
            "53       ملوث اُس دوبارہ سندھ پولیس حوالے چاہیےnegative\n",
            "54    کہڑہ جوک جنابpositive‍️چھڈو رھن دیو تہانوں گیم...\n",
            "Name: filtered_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def filter_short_posts(text):\n",
        "    return len(text.split()) >= 3\n",
        "\n",
        "\n",
        "data['filtered_text'] = data['cleaned_text1'].apply(lambda x: x if filter_short_posts(x) else None)\n",
        "\n",
        "# Drop rows with None values\n",
        "data.dropna(subset=['filtered_text'], inplace=True)\n",
        "print(data['filtered_text'].head(50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e439ee3b-c5c4-4c60-84ab-c706c608037a",
      "metadata": {
        "id": "e439ee3b-c5c4-4c60-84ab-c706c608037a",
        "outputId": "f4acae85-ef52-42ff-8a6a-d56d78705c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Preprocessed Urdu Text:\n",
            "                                            urdu_text\n",
            "0   positivepositivepositive لینے شادی فسادن ٹھیک ...\n",
            "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
            "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
            "4              مراد علی شاہ بھیس ڈی آئی آئی  حامد میر\n",
            "5                    قابل اعتبار قاتل اعتبار negative\n",
            "6                            انساں تھکا سوچوں سفر    \n",
            "7                      حامد میر ویلڈنpositivepositive\n",
            "8   یار وچارہ ویلا ہوندا آرے ہویا ہےpositivepositi...\n",
            "9   سمجھتے سارا پاکستان بیوقوف ھے positivepositive...\n",
            "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11      پائن دوبارہ فالو کرئیے   ؟ ؟ positivenegative\n",
            "12  کتنی مہنگائی الو دوسو روپے درجن کدو 80روپے گز ...\n",
            "13  positiveعشق راس آۓ negativeزخم کھاٶ گے positiv...\n",
            "15  خاتم  النبیین  محمدﷺ Surat 73 سورة المزمل Ayt ...\n",
            "16              بیچارے بیویاں ہیے تیسری ٹرائ positive\n",
            "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18              اللہ رحمتوں سائے مکمل صحت یاب فرمائے \n",
            "19   آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20  کھوتی بچیا،تیری اے،تیری قدر اے ۔ شکر بونڈ نئیں...\n",
            "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعے ن...\n",
            "22                         لڑکی positiveجیتی positive\n",
            "23  صدائیں درودوں رہینگی سن دل شاد گا، خدا اہلسنت ...\n",
            "24                              ووٹ بجائے ووٹر عزّت ️\n",
            "25  2004 نشئی کہا      اسٹیبلشمنٹ کتا وزیراعظم 201...\n",
            "26             مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27  پورے ہفتے سالن روٹی کھایا neutralneutralکوئی حال \n",
            "29  وھ کوئی ھو بیشک ھے ھو  کیمنا حرام ھو حق بات کا...\n",
            "30  ماضی انتہائی بے وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                             آمین ثمہ آمین positive\n",
            "32  جیتھے کھوتی وتھے آ کھلوتی positivepositiveposi...\n"
          ]
        }
      ],
      "source": [
        "data['urdu_text'] = data['filtered_text']\n",
        "print(\"Final Preprocessed Urdu Text:\")\n",
        "print(data[['urdu_text']].head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1940cff6-6ce2-4aa3-822b-a177f3f132b4",
      "metadata": {
        "id": "1940cff6-6ce2-4aa3-822b-a177f3f132b4"
      },
      "source": [
        "# Phase 2: Stemming and Lemmatization for Urdu Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5544517e-3f0d-4098-9b05-e6db685fb10a",
      "metadata": {
        "id": "5544517e-3f0d-4098-9b05-e6db685fb10a"
      },
      "source": [
        "STEMMING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b52c8e-6f3f-4409-aa90-d85f94677d05",
      "metadata": {
        "id": "67b52c8e-6f3f-4409-aa90-d85f94677d05"
      },
      "outputs": [],
      "source": [
        "def urdu_stemmer(text):\n",
        "    if isinstance(text, str):  # Check if the input is a string\n",
        "        stemmed_text = processor.urdu_stemmer(text)\n",
        "        return stemmed_text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da849731-84d2-4dbb-ba28-00590d4fae56",
      "metadata": {
        "id": "da849731-84d2-4dbb-ba28-00590d4fae56",
        "outputId": "d0175ae2-9888-44e5-a078-bc4cfeb5f70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         stemmed_text\n",
            "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
            "1   چل مہمانا کھانا سرو چڑیل چاچی نا دسدی آں میںpo...\n",
            "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
            "4               مراد علی شاہ بھیس ڈی آئی آئی حامد میر\n",
            "5                      قابل اعتبر قاتل اعتبر negative\n",
            "6                                 انساں تھکا سوچا سفر\n",
            "7                      حامد میر ویلڈنpositivepositive\n",
            "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
            "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
            "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11         پائن دوبرہ فالو کرئیہ ؟ ؟ positivenegative\n",
            "12  کتنی مہنگائی الو دوسو روپہ درجن کدو 80روپہ گز ...\n",
            "13  positiveعشق راس آۓ negativeزخم کھاٶ گہ positiv...\n",
            "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
            "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
            "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
            "19   آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20  کھوتی بچیا،تیری اہ،تیری قدر اہ ۔ شکر بونڈ نئا ...\n",
            "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
            "22                         لڑکی positiveجیتی positive\n",
            "23  صدائا درودا رہینگی سن دل شاد گا، خدا اہلسنت آب...\n",
            "24                              ووٹ بجائہ ووٹر عزّت ️\n",
            "25  2004 نشئی کہا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ ...\n",
            "26             مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27   پورہ ہفتہ سالن روٹی کھایا neutralneutralکوئی حال\n",
            "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
            "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                             آمین ثمہ آمین positive\n",
            "32  جیتھہ کھوتی وتھہ آ کھلوتی positivepositiveposi...\n",
            "33  اسمبلی ڈیزل چل اِسکو گدھا ھہ گدھہ ڈیزل ڈنڈہ ضر...\n",
            "34  عجیب به کامران خان ۔ پنگا گولی محو رقص ۔ پتہ چ...\n",
            "36  دروازہ اترتہ تھپڑ لگاتہ positivepositivepositi...\n",
            "37                    کلہاڑی مارنا کوئ سیکھہ positive\n",
            "38  دلہن پھپھو neutralneutralpositivepositiveposit...\n",
            "39  ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ positiv...\n",
            "40  محمد ندیم ملک بطور عام پاکستنی بلاول زرداری دل...\n",
            "41  قطری نانی ۔ ۔ بلو رانی ذلیل وقت چاہت ۔ ۔ ۔ ۔ p...\n",
            "42  بھائیا ویلکم لڑکی بہنا کرا نہیںneutralneutralp...\n",
            "43            موٹی چڑیل ٹویٹ positivepositivepositive\n",
            "44         ایتھہ تہ جج ۔ ۔ ۔ positivepositivepositive\n",
            "45  سارا دن پاک فوج خلاف بکواس ره فوجی گل ۔ ۔ ۔ po...\n",
            "46  لگت دیوت پورا پاکستن لکیرا سہارہ سوچت بولت ۔ ۔...\n",
            "47  ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا positivepositi...\n",
            "48  ضرورت الٹی کھوپڑی به کان سنو نکال positiveposi...\n",
            "49  سنا 1 اکیلا 1 11 گیارہ ۔ تریخ دفعہ 11 1 بربد ۔...\n",
            "50                  زندگی مصروف بھول یاد نہا اردو زبن\n",
            "52                 ہور ٹرک positive positive positive\n",
            "53      ملوث اُس دوبرہ سندھ پولیس حوالہ چاہیےnegative\n",
            "54  کہڑہ جوک جنابpositive‍️چھڈو رھن دیو تہانا گیم ...\n"
          ]
        }
      ],
      "source": [
        "data['stemmed_text'] = data['urdu_text'].apply(urdu_stemmer)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(data[[ 'stemmed_text']].head(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2303bf7-bb7d-4355-921b-8623d96ab53f",
      "metadata": {
        "id": "e2303bf7-bb7d-4355-921b-8623d96ab53f",
        "outputId": "914e8b3a-c321-44f3-b0cd-35d207fed3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Preprocessed Urdu Text:\n",
            "                                            urdu_text\n",
            "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
            "1   چل مہمانا کھانا سرو چڑیل چاچی نا دسدی آں میںpo...\n",
            "2   کامران خان دن بھریہ زمہ داری لگائی گئی اپوزیشن...\n",
            "4               مراد علی شاہ بھیس ڈی آئی آئی حامد میر\n",
            "5                      قابل اعتبر قاتل اعتبر negative\n",
            "6                                 انساں تھکا سوچا سفر\n",
            "7                      حامد میر ویلڈنpositivepositive\n",
            "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
            "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
            "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11         پائن دوبرہ فالو کرئیہ ؟ ؟ positivenegative\n",
            "12  کتنی مہنگائی الو دوسو روپہ درجن کدو 80روپہ گز ...\n",
            "13  positiveعشق راس آۓ negativeزخم کھاٶ گہ positiv...\n",
            "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
            "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
            "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
            "19   آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20  کھوتی بچیا،تیری اہ،تیری قدر اہ ۔ شکر بونڈ نئا ...\n",
            "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
            "22                         لڑکی positiveجیتی positive\n",
            "23  صدائا درودا رہینگی سن دل شاد گا، خدا اہلسنت آب...\n",
            "24                              ووٹ بجائہ ووٹر عزّت ️\n",
            "25  2004 نشئی کہا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ ...\n",
            "26             مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27   پورہ ہفتہ سالن روٹی کھایا neutralneutralکوئی حال\n",
            "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
            "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                             آمین ثمہ آمین positive\n",
            "32  جیتھہ کھوتی وتھہ آ کھلوتی positivepositiveposi...\n"
          ]
        }
      ],
      "source": [
        "data['urdu_text'] = data['stemmed_text']\n",
        "print(\"Final Preprocessed Urdu Text:\")\n",
        "print(data[['urdu_text']].head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b2178b-8aae-4017-8447-0e89c12ff97e",
      "metadata": {
        "id": "18b2178b-8aae-4017-8447-0e89c12ff97e"
      },
      "source": [
        "LEMMATIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6366f959-cf70-4903-a96d-bff2e433e5e9",
      "metadata": {
        "id": "6366f959-cf70-4903-a96d-bff2e433e5e9"
      },
      "outputs": [],
      "source": [
        "def urdu_lemmatizer(text):\n",
        "    if isinstance(text, str):\n",
        "        lemmatized_text = processor.lemmatize_sentence(text)\n",
        "        return lemmatized_text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a7c2aa-092c-4130-823b-29f4cfcec6a2",
      "metadata": {
        "id": "a2a7c2aa-092c-4130-823b-29f4cfcec6a2",
        "outputId": "f0e8dd98-5622-428d-9d05-7ca50281d599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                      lemmatized_text\n",
            "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
            "1   چلنا مہمانا کھا سرا چڑیل چاچی نا دسدی آں میںpo...\n",
            "2   کامران خان دن بھریہ زمہ داری لگنا جانا اپوزیشن...\n",
            "4               مراد علی شاہ بھیس ڈی آئی آئی حامد میر\n",
            "5                      قابل اعتبر قاتل اعتبر negative\n",
            "6                               انساں تھکنا سوچنا سفر\n",
            "7                      حامد میر ویلڈنpositivepositive\n",
            "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
            "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
            "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11         پائن دوبرہ فالو کرئیہ ؟ ؟ positivenegative\n",
            "12  کتنا مہنگائی الہ دوسو روپہ درجن کدہ 80روپہ گز ...\n",
            "13  positiveعشق راس آۓ negativeزخم کھاٶ گہ positiv...\n",
            "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
            "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
            "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
            "19   آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20  کھونا بچیا،تیری اہ،تیری قدر اہ ۔ شکر بونڈ نئا ...\n",
            "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
            "22                         لڑکی positiveجیتی positive\n",
            "23  صدائا درودا رہینگی سننا دل شاد گا، خدا اہلسنت ...\n",
            "24                              ووٹ بجائہ ووٹر عزّت ️\n",
            "25  2004 نشئی کہنا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ...\n",
            "26             مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27   پورہ ہفتہ سالن روٹی کھانا neutralneutralکوئی حال\n",
            "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
            "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                             آمین ثمہ آمین positive\n",
            "32  جیتھہ کھونا وتھہ آنا کھلوتی positivepositivepo...\n",
            "33  اسمبلی ڈیزل چلنا اِسکو گدھا ھہ گدھہ ڈیزل ڈنڈہ ...\n",
            "34  عجیب به کامران خان ۔ پنگا گولی محو رقص ۔ پتہ چ...\n",
            "36  دروازہ اترتہ تھپڑ لگاتہ positivepositivepositi...\n",
            "37                    کلہاڑی مرْنا کوئ سیکھہ positive\n",
            "38  دلہن پھپھو neutralneutralpositivepositiveposit...\n",
            "39  ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا کمینہ positiv...\n",
            "40  محمد ندیم ملک بطور عام پاکستنی بلاول زرداری دل...\n",
            "41  قطری نانی ۔ ۔ بل رانی ذلیل وقت چاہت ۔ ۔ ۔ ۔ po...\n",
            "42  بھائیا ویلکم لڑکی بہنا کرنا نہیںneutralneutral...\n",
            "43            موٹی چڑیل ٹویٹ positivepositivepositive\n",
            "44         ایتھہ تہ جج ۔ ۔ ۔ positivepositivepositive\n",
            "45  سارا دن پاک فوج خلاف بکواس ره فوجی گل ۔ ۔ ۔ po...\n",
            "46  لگت دیوت پورا پاکستن لکیرا سہارہ سوچت بولت ۔ ۔...\n",
            "47  ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا positivepositi...\n",
            "48  ضرورت الٹنا کھوپڑی به کان سننا نکلنا positivep...\n",
            "49  سننا 1 اکیلا 1 11 گیارہ ۔ تریخ دفعہ 11 1 بربد ...\n",
            "50              زندگی مصروف بھولنا یاد نہانا اردو زبن\n",
            "52                 ہور ٹرک positive positive positive\n",
            "53      ملوث اُس دوبرہ سندھ پولیس حوالہ چاہیےnegative\n",
            "54  کہڑہ جوک جنابpositive‍️چھڈو رھن دیا تہانا گیم ...\n"
          ]
        }
      ],
      "source": [
        "data['lemmatized_text'] = data['urdu_text'].apply(urdu_lemmatizer)\n",
        "\n",
        "\n",
        "print(data[['lemmatized_text']].head(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eede037e-0ad9-433d-95a8-208e34df32c3",
      "metadata": {
        "id": "eede037e-0ad9-433d-95a8-208e34df32c3",
        "outputId": "37169ede-f077-406d-99d9-289a45740e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Preprocessed Urdu Text:\n",
            "                                            urdu_text\n",
            "0   positivepositivepositive لینہ شادی فسادن ٹھیک ...\n",
            "1   چلنا مہمانا کھا سرا چڑیل چاچی نا دسدی آں میںpo...\n",
            "2   کامران خان دن بھریہ زمہ داری لگنا جانا اپوزیشن...\n",
            "4               مراد علی شاہ بھیس ڈی آئی آئی حامد میر\n",
            "5                      قابل اعتبر قاتل اعتبر negative\n",
            "6                               انساں تھکنا سوچنا سفر\n",
            "7                      حامد میر ویلڈنpositivepositive\n",
            "8   یار وچارہ ویلا ہوندا آرہ ہویا ہےpositivepositi...\n",
            "9   سمجھتہ سارا پاکستن بیوقوف ھہ positivepositivep...\n",
            "10    تسی لڑاںٔی کروانی ساڈی positivepositivepositive\n",
            "11         پائن دوبرہ فالو کرئیہ ؟ ؟ positivenegative\n",
            "12  کتنا مہنگائی الہ دوسو روپہ درجن کدہ 80روپہ گز ...\n",
            "13  positiveعشق راس آۓ negativeزخم کھاٶ گہ positiv...\n",
            "15  خاتم النبیین محمدﷺ Surat 73 سوره المزمل Ayt 20...\n",
            "16                بیچارہ بیوی ہیہ تیسری ٹرائ positive\n",
            "17              پتہ ہورہا بورڈ زنگ ہےnegativenegative\n",
            "18                 اللہ رحمت سائہ مکمل صحت یاب فرمائہ\n",
            "19   آرمی چیف نوٹس ۔ مجرم جرائیم نوٹس کرےگا ۔ neutral\n",
            "20  کھونا بچیا،تیری اہ،تیری قدر اہ ۔ شکر بونڈ نئا ...\n",
            "21  فوج سیاست دور ۔ بلاول زرداری فوج کراچی واقعہ ن...\n",
            "22                         لڑکی positiveجیتی positive\n",
            "23  صدائا درودا رہینگی سننا دل شاد گا، خدا اہلسنت ...\n",
            "24                              ووٹ بجائہ ووٹر عزّت ️\n",
            "25  2004 نشئی کہنا اسٹیبلشمنٹ کت وزیراعظم 2018 کتہ...\n",
            "26             مشکل ناممکن کامران کوشش ۔ ۔ ؟ positive\n",
            "27   پورہ ہفتہ سالن روٹی کھانا neutralneutralکوئی حال\n",
            "29  وھ کوئی ھو بیشک ھہ ھو کیمنا حرام ھو حق به کامر...\n",
            "30  ماضی انتہائی بہ وقوف حال سمجھدار لڑکی ہوںposit...\n",
            "31                             آمین ثمہ آمین positive\n",
            "32  جیتھہ کھونا وتھہ آنا کھلوتی positivepositivepo...\n"
          ]
        }
      ],
      "source": [
        "data['urdu_text'] = data['lemmatized_text']\n",
        "print(\"Final Preprocessed Urdu Text:\")\n",
        "print(data[['urdu_text']].head(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba002ce2-0af4-4e0d-b199-7ac1b00ed6e2",
      "metadata": {
        "id": "ba002ce2-0af4-4e0d-b199-7ac1b00ed6e2"
      },
      "source": [
        "# Phase 3: Feature Extraction from Urdu Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8c2d2a5-06f5-4d35-bfb6-879de26517a9",
      "metadata": {
        "id": "d8c2d2a5-06f5-4d35-bfb6-879de26517a9"
      },
      "source": [
        " Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ccd2e6-813b-45c5-b5ab-66e9f3e57f01",
      "metadata": {
        "id": "d4ccd2e6-813b-45c5-b5ab-66e9f3e57f01"
      },
      "outputs": [],
      "source": [
        "def urdu_tokenize(text):\n",
        "    if isinstance(text, str):  # Check if the input is a string\n",
        "        tokens = processor.urdu_tokenize(text)  # Tokenize using the LughatNLP processor\n",
        "        return tokens\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64256430-145d-4841-b1ad-38a489c99816",
      "metadata": {
        "id": "64256430-145d-4841-b1ad-38a489c99816",
        "outputId": "fda7fe90-826a-40f8-cbb3-b1ef77388305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               tokens\n",
            "0                     [لینہ, شادی, فسادن, ٹھیک, کوجی]\n",
            "1   [چلنا, مہمانا, کھا, سرا, چڑیل, چاچی, نا, دسدی,...\n",
            "2   [کامران, خان, دن, بھریہ, زمہ, داری, لگنا, جانا...\n",
            "4     [مراد, علی, شاہ, بھیس, ڈی, آئی, آئی, حامد, میر]\n",
            "5                          [قابل, اعتبر, قاتل, اعتبر]\n",
            "6                          [انساں, تھکنا, سوچنا, سفر]\n",
            "7                                  [حامد, میر, ویلڈن]\n",
            "8   [یار, وچارہ, ویلا, ہوندا, آرہ, ہویا, ہے, تسی, ...\n",
            "9                  [سمجھتہ, سارا, پاکستن, بیوقوف, ھہ]\n",
            "10                        [تسی, لڑاںٔی, کروانی, ساڈی]\n",
            "11                   [پائن, دوبرہ, فالو, کرئیہ, ؟, ؟]\n",
            "12  [کتنا, مہنگائی, الہ, دوسو, روپہ, درجن, کدہ, 80...\n",
            "13         [عشق, راس, آۓ, زخم, کھاٶ, گہ, مُسکراٶ, گہ]\n",
            "15  [خاتم, النبیین, محمدﷺ, 73, سوره, المزمل, 20, ح...\n",
            "16                   [بیچارہ, بیوی, ہیہ, تیسری, ٹرائ]\n",
            "17                        [پتہ, ہورہا, بورڈ, زنگ, ہے]\n",
            "18         [اللہ, رحمت, سائہ, مکمل, صحت, یاب, فرمائہ]\n",
            "19  [آرمی, چیف, نوٹس, ۔, مجرم, جرائیم, نوٹس, کرےگا...\n",
            "20  [کھونا, بچیا،تیری, اہ،تیری, قدر, اہ, ۔, شکر, ب...\n",
            "21  [فوج, سیاست, دور, ۔, بلاول, زرداری, فوج, کراچی...\n",
            "22                                       [لڑکی, جیتی]\n",
            "23  [صدائا, درودا, رہینگی, سننا, دل, شاد, گا،, خدا...\n",
            "24                        [ووٹ, بجائہ, ووٹر, عزّت, ️]\n",
            "25  [2004, نشئی, کہنا, اسٹیبلشمنٹ, کت, وزیراعظم, 2...\n",
            "26              [مشکل, ناممکن, کامران, کوشش, ۔, ۔, ؟]\n",
            "27         [پورہ, ہفتہ, سالن, روٹی, کھانا, کوئی, حال]\n",
            "29  [وھ, کوئی, ھو, بیشک, ھہ, ھو, کیمنا, حرام, ھو, ...\n",
            "30  [ماضی, انتہائی, بہ, وقوف, حال, سمجھدار, لڑکی, ...\n",
            "31                                  [آمین, ثمہ, آمین]\n",
            "32                  [جیتھہ, کھونا, وتھہ, آنا, کھلوتی]\n",
            "33  [اسمبلی, ڈیزل, چلنا, اِسکو, گدھا, ھہ, گدھہ, ڈی...\n",
            "34  [عجیب, به, کامران, خان, ۔, پنگا, گولی, محو, رق...\n",
            "36                       [دروازہ, اترتہ, تھپڑ, لگاتہ]\n",
            "37                        [کلہاڑی, مرْنا, کوئ, سیکھہ]\n",
            "38                                      [دلہن, پھپھو]\n",
            "39          [ہاہاہاہاہاہاہاہاہاہاہاہاہاہاہاہا, کمینہ]\n",
            "40  [محمد, ندیم, ملک, بطور, عام, پاکستنی, بلاول, ز...\n",
            "41  [قطری, نانی, ۔, ۔, بل, رانی, ذلیل, وقت, چاہت, ...\n",
            "42  [بھائیا, ویلکم, لڑکی, بہنا, کرنا, نہیں, بلی, ز...\n",
            "43                                 [موٹی, چڑیل, ٹویٹ]\n",
            "44                           [ایتھہ, تہ, جج, ۔, ۔, ۔]\n",
            "45  [سارا, دن, پاک, فوج, خلاف, بکواس, ره, فوجی, گل...\n",
            "46  [لگت, دیوت, پورا, پاکستن, لکیرا, سہارہ, سوچت, ...\n",
            "47  [ہاہاہاہاہاہاہاہاہاہاہااہاہاہاہا, لگدا, اہ, می...\n",
            "48       [ضرورت, الٹنا, کھوپڑی, به, کان, سننا, نکلنا]\n",
            "49  [سننا, 1, اکیلا, 1, 11, گیارہ, ۔, تریخ, دفعہ, ...\n",
            "50      [زندگی, مصروف, بھولنا, یاد, نہانا, اردو, زبن]\n",
            "52                                         [ہور, ٹرک]\n",
            "53      [ملوث, اُس, دوبرہ, سندھ, پولیس, حوالہ, چاہیے]\n",
            "54  [کہڑہ, جوک, جناب, ‍, ️, چھڈو, رھن, دیا, تہانا,...\n"
          ]
        }
      ],
      "source": [
        "data['tokens'] = data['urdu_text'].apply(urdu_tokenize)\n",
        "print(data[[ 'tokens']].head(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38177d1-4bc5-4b5d-8d93-836e75e214d6",
      "metadata": {
        "id": "b38177d1-4bc5-4b5d-8d93-836e75e214d6"
      },
      "source": [
        " Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840c4752-373e-4c9e-ba25-a8395048c13a",
      "metadata": {
        "id": "840c4752-373e-4c9e-ba25-a8395048c13a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f495f40a-bf44-4551-8168-960efc7cb7b8",
      "metadata": {
        "id": "f495f40a-bf44-4551-8168-960efc7cb7b8"
      },
      "source": [
        "Tf-IDF (Term Frequency-Inverse Document Frequency):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf5dad1-560a-4626-875d-106015ea6313",
      "metadata": {
        "id": "2bf5dad1-560a-4626-875d-106015ea6313",
        "outputId": "854d2816-d034-4c53-c5e8-13253fbcc829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Words with Highest TF-IDF Scores:\n",
            "                       Word  Mean_TF_IDF_Score\n",
            "0                  positive           0.027201\n",
            "1          positivepositive           0.013750\n",
            "2  positivepositivepositive           0.011043\n",
            "3                      کوئی           0.010329\n",
            "4                      اللہ           0.010233\n",
            "5                       خان           0.010041\n",
            "6                        ھہ           0.009844\n",
            "7                        به           0.009398\n",
            "8                      سندھ           0.007996\n",
            "9                        نا           0.007666\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "#\n",
        "corpus = data['urdu_text'].dropna().tolist()  # Drop any NaN values\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to create the TF-IDF matrix\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (words) and their corresponding TF-IDF scores\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "dense = tfidf_matrix.todense()\n",
        "\n",
        "# Create a DataFrame with TF-IDF scores\n",
        "tfidf_df = pd.DataFrame(dense, columns=feature_names)\n",
        "\n",
        "mean_tfidf_scores = tfidf_df.mean(axis=0).sort_values(ascending=False)\n",
        "\n",
        "# Get the top 10 words with the highest TF-IDF scores\n",
        "top_tfidf_words = mean_tfidf_scores.head(10).reset_index()\n",
        "top_tfidf_words.columns = ['Word', 'Mean_TF_IDF_Score']\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nTop 10 Words with Highest TF-IDF Scores:\")\n",
        "print(top_tfidf_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9eaafe-b453-47c4-a511-02fdc32333a9",
      "metadata": {
        "id": "9b9eaafe-b453-47c4-a511-02fdc32333a9"
      },
      "source": [
        " Word2Vec:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "859b966f-6f59-4910-ac07-d21c96300185",
      "metadata": {
        "id": "859b966f-6f59-4910-ac07-d21c96300185",
        "outputId": "c4e0efb1-1eca-46e5-9b34-128e27522140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 Words Most Similar to 'اچھا':\n",
            "دیکھتہ: 0.9307\n",
            "واکا: 0.9306\n",
            "ہورہی: 0.9299\n",
            "ڈیزل: 0.9296\n",
            "کاکول: 0.9289\n"
          ]
        }
      ],
      "source": [
        "# Prepare the tokenized text for Word2Vec training\n",
        "tokenized_texts =data['tokens'].tolist()\n",
        "\n",
        "# Train the Word2Vec model using the tokenized text\n",
        "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=8, min_count=2, workers=4)\n",
        "\n",
        "# List the top 5 words most similar to the word \"اچھا\" (good)\n",
        "try:\n",
        "    similar_words = word2vec_model.wv.most_similar(\"اچھا\", topn=5)\n",
        "    print(\"\\nTop 5 Words Most Similar to 'اچھا':\")\n",
        "    for word, similarity in similar_words:\n",
        "        print(f\"{word}: {similarity:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"\\nThe word 'اچھا' is not in the vocabulary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672cdb6c-b62f-4f00-aa9e-9eb0d278f9cc",
      "metadata": {
        "id": "672cdb6c-b62f-4f00-aa9e-9eb0d278f9cc",
        "outputId": "dc9cd397-d8c5-4260-ebb8-417bd1cdf1fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Tokenized Texts:\n",
            "['لینہ', 'شادی', 'فسادن', 'ٹھیک', 'کوجی']\n",
            "['چلنا', 'مہمانا', 'کھا', 'سرا', 'چڑیل', 'چاچی', 'نا', 'دسدی', 'آں', 'میں']\n",
            "['کامران', 'خان', 'دن', 'بھریہ', 'زمہ', 'داری', 'لگنا', 'جانا', 'اپوزیشن', 'کردار', 'کشی', 'اوراس', 'پربھونکناہےآپ', 'خوشامدگری', 'وچاپلوسی', 'سےاورکتنی', 'دولت', 'کماناچاہتےہا', 'موٹرسائیکل', 'سےپیجارو', 'پراڈو', 'کےسفرما', 'ضمیرکی', 'لاش', 'سےاٹھتی', 'بدبوآپ', 'ناک', 'نوٹ', 'سےالتجاگزارش', 'ہےہما', 'فالوکرا']\n",
            "['مراد', 'علی', 'شاہ', 'بھیس', 'ڈی', 'آئی', 'آئی', 'حامد', 'میر']\n",
            "['قابل', 'اعتبر', 'قاتل', 'اعتبر']\n",
            "Vocabulary Size: 20801\n",
            "Vocabulary Sample: ['۔', '؟', '️', 'کوئی', 'خان', 'ھہ', 'اللہ', 'به', 'پاکستن', 'سندھ', 'گہ', 'کہنا', 'آئی', 'نواز', 'عمران', 'حکومت', 'لوگ', 'اہ', 'تنقید', '…']\n",
            "\n",
            "Top 5 Words Most Similar to 'اچھا':\n",
            "ٹرانسپورٹ: 0.8969\n",
            "وہم: 0.8958\n",
            "اون: 0.8956\n",
            "ذیادہ: 0.8955\n",
            "ﺭﮨﻨﺎ: 0.8955\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Assuming 'tokens' column contains tokenized text\n",
        "tokenized_texts = data['tokens'].tolist()\n",
        "\n",
        "# Print sample of tokenized texts to inspect\n",
        "print(\"Sample Tokenized Texts:\")\n",
        "for tokens in tokenized_texts[:5]:\n",
        "    print(tokens)\n",
        "\n",
        "# Train the Word2Vec model using the tokenized text with min_count=1\n",
        "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Check vocabulary size and sample\n",
        "print(\"Vocabulary Size:\", len(word2vec_model.wv.key_to_index))\n",
        "print(\"Vocabulary Sample:\", list(word2vec_model.wv.key_to_index)[:20])\n",
        "\n",
        "# Find the top 5 words most similar to 'اچھا' (good)\n",
        "try:\n",
        "    similar_words = word2vec_model.wv.most_similar(\"اچھا\", topn=5)\n",
        "    print(\"\\nTop 5 Words Most Similar to 'اچھا':\")\n",
        "    for word, similarity in similar_words:\n",
        "        print(f\"{word}: {similarity:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"\\nThe word 'اچھا' is not in the vocabulary.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e0d425-d1dd-4c3b-928b-b841a9bad984",
      "metadata": {
        "id": "55e0d425-d1dd-4c3b-928b-b841a9bad984"
      },
      "source": [
        "# Phase 4: N-grams Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3c28ad-8c28-4a72-8529-7cb1448ce2bf",
      "metadata": {
        "id": "aa3c28ad-8c28-4a72-8529-7cb1448ce2bf"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc38105-b3c3-497f-a854-1f09e045c839",
      "metadata": {
        "id": "9fc38105-b3c3-497f-a854-1f09e045c839"
      },
      "source": [
        "UNIGRAMS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92919c37-e601-4229-851e-ba5ce90d98e8",
      "metadata": {
        "id": "92919c37-e601-4229-851e-ba5ce90d98e8"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = data['tokens'].tolist()  # Tokenized Urdu text as lists of words\n",
        "\n",
        "# Flatten the tokenized texts for unigram analysis\n",
        "all_words = [word for tokens in tokenized_texts for word in tokens]\n",
        "\n",
        "# Unigrams\n",
        "unigram_freq = Counter(all_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837c1614-c8c6-46c6-91a3-a3059301f765",
      "metadata": {
        "id": "837c1614-c8c6-46c6-91a3-a3059301f765",
        "outputId": "b5c09bc9-6b4f-4f8d-8547-ae5de20b4f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Unigrams:\n",
            "۔: 11567\n",
            "؟: 1582\n",
            "️: 1555\n",
            "خان: 1172\n",
            "کوئی: 1172\n",
            "ھہ: 1066\n",
            "اللہ: 996\n",
            "به: 976\n",
            "پاکستن: 859\n",
            "سندھ: 815\n"
          ]
        }
      ],
      "source": [
        "top_unigrams = unigram_freq.most_common(10)\n",
        "print(\"\\nTop 10 Unigrams:\")\n",
        "for word, freq in top_unigrams:\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0decf9f-bd38-4a42-94ba-ddc62fac31fb",
      "metadata": {
        "id": "c0decf9f-bd38-4a42-94ba-ddc62fac31fb"
      },
      "source": [
        "BIGRAMS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a79c259-9896-43ab-8896-cff8e8c936f6",
      "metadata": {
        "id": "4a79c259-9896-43ab-8896-cff8e8c936f6"
      },
      "outputs": [],
      "source": [
        "bigram_list = [list(ngrams(tokens, 2)) for tokens in tokenized_texts]\n",
        "bigrams = [bigram for sublist in bigram_list for bigram in sublist]  # Flatten\n",
        "bigram_freq = Counter(bigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e26fc9-9531-475e-b1bc-8fe7159f7304",
      "metadata": {
        "id": "f6e26fc9-9531-475e-b1bc-8fe7159f7304",
        "outputId": "62368c50-f0c3-42b8-dba8-6dbcc3a59495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Bigrams:\n",
            "('۔', '۔'): 4706\n",
            "('عمران', 'خان'): 508\n",
            "('؟', '؟'): 496\n",
            "('نواز', 'شریف'): 448\n",
            "('\\u200d', '️'): 332\n",
            "('سندھ', 'پولیس'): 307\n",
            "('️', '️'): 260\n",
            "('آرمی', 'چیف'): 223\n",
            "('کیپٹن', 'صفدر'): 179\n",
            "('اردو', 'زبن'): 172\n"
          ]
        }
      ],
      "source": [
        "top_bigrams = bigram_freq.most_common(10)\n",
        "print(\"\\nTop 10 Bigrams:\")\n",
        "for bigram, freq in top_bigrams:\n",
        "    print(f\"{bigram}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c206897-5f15-4a44-9144-866051840c30",
      "metadata": {
        "id": "7c206897-5f15-4a44-9144-866051840c30"
      },
      "source": [
        "TRIGRAMS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ac7e3f-9b23-4d3e-9139-4bb50579d544",
      "metadata": {
        "id": "52ac7e3f-9b23-4d3e-9139-4bb50579d544"
      },
      "outputs": [],
      "source": [
        "trigram_list = [list(ngrams(tokens, 3)) for tokens in tokenized_texts]\n",
        "trigrams = [trigram for sublist in trigram_list for trigram in sublist]  # Flatten\n",
        "trigram_freq = Counter(trigrams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda488d2-fb8c-4ce4-b352-a5b5cba1040c",
      "metadata": {
        "id": "dda488d2-fb8c-4ce4-b352-a5b5cba1040c",
        "outputId": "4fc00042-e7f1-48b2-c611-7856a97fc205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Trigrams:\n",
            "('۔', '۔', '۔'): 2310\n",
            "('؟', '؟', '؟'): 234\n",
            "('\\u2066', '️', '\\u2069'): 130\n",
            "('️', '️', '️'): 121\n",
            "('\\u200d', '️', '\\u200d'): 117\n",
            "('️', '\\u200d', '️'): 116\n",
            "('پینا', 'ٹی', 'آئی'): 114\n",
            "('پینا', 'ڈی', 'ایم'): 88\n",
            "('صلی', 'اللہ', 'علیہ'): 88\n",
            "('جزاک', 'اللہ', 'خیر'): 74\n"
          ]
        }
      ],
      "source": [
        "top_trigrams = trigram_freq.most_common(10)\n",
        "print(\"\\nTop 10 Trigrams:\")\n",
        "for trigram, freq in top_trigrams:\n",
        "    print(f\"{trigram}: {freq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f0f52e-e437-43f8-95fa-ded07486aec5",
      "metadata": {
        "id": "f4f0f52e-e437-43f8-95fa-ded07486aec5"
      },
      "source": [
        "# Phase 5: Sentiment Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e89070d-9248-4479-b440-fbdb09caf1b8",
      "metadata": {
        "id": "6e89070d-9248-4479-b440-fbdb09caf1b8"
      },
      "source": [
        "using tf-idf matrix calculated above with NAIVE BAYES CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c39013-894b-431f-ae7a-6b109816d576",
      "metadata": {
        "id": "95c39013-894b-431f-ae7a-6b109816d576",
        "outputId": "b62fa06f-6c1a-4fdd-eccd-87217e55aed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7571\n",
            "Precision: 0.7067\n",
            "Recall: 0.9092\n",
            "F1 Score: 0.7953\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming 'tfidf_matrix' contains your features and 'data' has the labels\n",
        "X = tfidf_matrix\n",
        "y = data['is_sarcastic']  # replace with your actual label column\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23dfc004-7046-4ff4-ba3c-617934dfae27",
      "metadata": {
        "id": "23dfc004-7046-4ff4-ba3c-617934dfae27"
      },
      "source": [
        "# Phase 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f786d275-b800-4995-a571-745e129f17af",
      "metadata": {
        "id": "f786d275-b800-4995-a571-745e129f17af"
      },
      "source": [
        "# 1. Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29fd9bbb-9ae4-48ae-92ad-7add640ef317",
      "metadata": {
        "id": "29fd9bbb-9ae4-48ae-92ad-7add640ef317"
      },
      "source": [
        "# Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d094b78a-5a85-48a5-8faf-738ae379c102",
      "metadata": {
        "id": "d094b78a-5a85-48a5-8faf-738ae379c102"
      },
      "source": [
        "The sentiment analysis model achieved an accuracy of 75.71%, with precision at 70.67%, recall at 90.92%, and an F1 score of 79.53%. These metrics suggest that while the model is effective at identifying positive sentiments, it tends to miss some negative sentiments, leading to a lower precision score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a939dfed-0ab6-49d6-9fd5-e34049cc77b1",
      "metadata": {
        "id": "a939dfed-0ab6-49d6-9fd5-e34049cc77b1"
      },
      "source": [
        "# Challenges with Stemming and Lemmatization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e5df27-54f0-4177-a051-e401cbb832c2",
      "metadata": {
        "id": "56e5df27-54f0-4177-a051-e401cbb832c2"
      },
      "source": [
        "One significant challenge is stemming and lemmatization. The rich morphology of Urdu makes it difficult to identify root forms of words accurately. This can result in the model misinterpreting meanings, especially in complex sentences or sarcastic expressions, which require a deeper understanding of context."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fafba80-7b79-415c-bbf1-5b5ef5e31ea0",
      "metadata": {
        "id": "6fafba80-7b79-415c-bbf1-5b5ef5e31ea0"
      },
      "source": [
        "# Areas for Improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b6d007-b121-4513-ba71-3b0e2fbbbc19",
      "metadata": {
        "id": "b2b6d007-b121-4513-ba71-3b0e2fbbbc19"
      },
      "source": [
        "To enhance the model's performance, we should refine preprocessing techniques for better handling of word variations. Additionally, integrating contextual embeddings or pre-trained models that understand the nuances of Urdu could lead to improvements in identifying sentiments accurately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a188f45b-bb12-48c6-817d-de5cafe34d64",
      "metadata": {
        "id": "a188f45b-bb12-48c6-817d-de5cafe34d64"
      },
      "source": [
        "# 2. Challenges in Urdu Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ee836d-a3c7-47de-9daf-bd971b18b006",
      "metadata": {
        "id": "c8ee836d-a3c7-47de-9daf-bd971b18b006"
      },
      "source": [
        "# Complex Morphology\n",
        "Urdu’s intricate word structure complicates stemming and lemmatization processes. This complexity can lead to the loss of essential context during text analysis, resulting in inaccurate sentiment classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91930ff0-d722-44fd-be51-02f70a8e52bb",
      "metadata": {
        "id": "91930ff0-d722-44fd-be51-02f70a8e52bb"
      },
      "source": [
        "# Colloquial Language\n",
        "The informal nature of language used on social media introduces slang, abbreviations, and unique expressions, which are often absent in formal Urdu. This variation makes it challenging for the model to capture sentiments accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cccd9411-443d-4f42-ae13-76d6ef0e3ea3",
      "metadata": {
        "id": "cccd9411-443d-4f42-ae13-76d6ef0e3ea3"
      },
      "source": [
        "# Noisy Data\n",
        "Social media platforms often contain noisy data, including emojis, misspellings, and unconventional grammar. Such noise can hinder the model’s ability to extract clear sentiment signals.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b444fad-d9af-465f-8f70-71e0f3becd44",
      "metadata": {
        "id": "7b444fad-d9af-465f-8f70-71e0f3becd44"
      },
      "source": [
        "# Optimizing the NLP Pipeline\n",
        "To improve our Urdu sentiment analysis, we should focus on better data normalization techniques and expand the training dataset to include a wider range of colloquial expressions. Utilizing advanced language models that better capture context will also enhance the model's accuracy and robustness in sentiment classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f61ca276-d16e-447c-b4d2-f39494eb37e5",
      "metadata": {
        "id": "f61ca276-d16e-447c-b4d2-f39494eb37e5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be5015e-370a-46d1-bd70-095a084edab4",
      "metadata": {
        "id": "7be5015e-370a-46d1-bd70-095a084edab4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}